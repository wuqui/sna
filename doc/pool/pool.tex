
\section{Modeling the diffusion of lexical innovations}
  \label{sec:modeling-diff}

Speakers continually coin new words, yet most fail to spread successfully and fall into oblivion. How do new words diffuse to be known and used by more and more speakers and to become conventional lexemes in a language system? And how can diffusion be modelled theoretically and measured empirically?

Neologisms are on a continuum from entirely novel word-formations to established lexemes that are familiar to the majority of the speech community. Neologisms have spread to some extent, but are still perceived as new or unknown by many speakers. On one end of the continuum, \enquote{nonce-formations} are new words that have been coined in a concrete communicative situation, but are not adopted by interlocutors to be used in future usage contexts and do not enter a process of continuous diffusion.~ \parencite{Hohenhaus1996AdhocWortbildungTerminologie}

Fully established words form the other end of the continuum. They are known and used by the majority of the speech community, and they are codified in dictionaries. This latter, lexicographic feature reflects speakers' agreement on how these words are to be used and marks their status as conventional lexical units in the language system. Neologisms occupy an intermediate position between both poles and can be defined as

\blockquote[{\cite[31]{Kerremans2015WebNew}}]{
[\dots] lexical units, that have been manifested in use and thus are no longer nonce-formations, but have not yet occurred frequently and are not widespread enough in a given period to have become part and parcel of the lexicon of the speech community and the majority of its members.
}

Diffusion thus represents the process that transports successful neologisms along this continuum, becoming increasingly conventional in the speech community.

S-curve model

EC model

  A more precise definition is provided by \citeauthor{Schmid2020DynamicsLinguistic}: \blockquote[\cite{Schmid2020DynamicsLinguistic}]{I define diffusion as a process that brings about a change in the number of speakers and communities who conform to a regularity of co-semiotic behaviour and a change in the types of cotexts and contexts in which they conform to it.} \todo{page?}

  this definition includes three dimensions of diffusion

    cotexts
    contexts
    speakers: number and groups

  i will focus on sociolinguistic dimension in this paper
    spread across
      speakers
      communities

  context: largely fixed as it is limited to use on Twitter
    comparison of contexts outside the scope of this paper; initial work: \parencite{Wurschinger2016UsingWeb}

previous work has taken at
  structural and
  cognitive perspectives

i will focus on the sociolinguistic perspective



  \subsection{Research perspectives}
    \label{subsec:research-perspectives}

  A substantial body of linguistic research has tackled this question from different \hw{perspectives}. \parencite[16]{Schmid2016EnglishMorphology}

  From a \hw{structural} perspective, main areas of interest include which word-formation processes are involved in forming new words, whether they are formally and semantically transparent, whether they change in the process of lexicalization and which status the resulting neologisms have in the language system (institutionalization). \parencite[e.g.][]{Bauer1983EnglishWordformation, Lipka2005LexicalizationInstitutionalization}

  \hw{Cognitive} perspectives focus on how individuals process and store lexical innovations. Speakers generally use new words when they experience a communicative need to talk about entities or practices that cannot be readily expressed by their language's inventory of conventional words yet. In order for neologisms to successfully diffuse, speakers need to successfully negotiate their meaning (co-semiosis) in discourse, others need to adopt the behaviour of using these words (co-adaption). Continued exposure and use of new words can then lead to the entrenchment of new words in the mental lexicon of speakers.~\parencite{Schmid2008NewWords}

  \hw{Sociolinguistic} perspectives transcend the level of the individual to study the diffusion of new words across speakers. The diffusion of lexical innovations is commonly seen as successful when the majority of the speech community has accepted a new word as a conventional lexical unit which is commonly used in communicative practice.


  \subsection{The S-curve model}
    \label{subsec:s-curve-model}

  \hw{S-curve models} of linguistic change~\parencite{Milroy1992LinguisticVariation, Nevalainen2015DescriptiveAdequacy, Labov2007TransmissionDiffusion} assume universal sociolinguistic dynamics for the diffusion of linguistic innovations.

  \begin{easylist}[itemize]

  # The \hw{trajectory} of spread is expected to follow an S-curve shape, with low rates of diffusion in early stages, followed by a period of accelerating spread with a tipping point at the mid point in the diffusion curve after which diffusion slows down and the curve flattens towards the end of the diffusion process.

  # These temporal trajectories are assumed to correspond to the \hw{sociolinguistic dynamics} of which individuals and groups interact with each other and adopt the target innovation.

  ## In the \hw{first stage} of slow diffusion only few early adopters take up the innovative words. Individuals who use the new word in this stage typically form dense networks which are connected by strong ties. The structure of tight-knit communities of closely-associated individuals facilitates the successful negotiation of meaning (co-semiosis) of new words. High rates of interactions in these communities lead to high rates of exposure for individuals, which fosters co-adaption, entrenchment and the increasing usualization of new words in these communities.

  ## In cases of successful diffusion the initial stages are followed by an \hw{acceleration in spread} when new words increasingly reach speakers outside these tight-knit communities via weak ties~\parencite{Granovetter1977StrengthWeak}. Rates of diffusion increase substantially when speakers who are not part of the initial group of early adopters start to accommodate the new words, allowing the innovations to reach a broader spectrum of the speech community.

  ## In \hw{later stages}, rates of diffusion slow down again as the majority of the speech community has already adopted the new words, while a minority of speakers remains reluctant to take up the new words.

  # S-curve models have mainly been applied to the \hw{linguistic domains} of phonology and syntax. Fundamental differences between lexemes and linguistic items on other levels such as phonemes and grammatical constructions might affect the validity and reliability of such models for \emph{lexical} innovation.

  ## For example, grammatical constructions such as the \ol{going to} future used to express a speaker's future intention serve to fulfil relatively abstract communicative needs that remain stable over time. By contrast, on the lexical level, linguistic innovations are typically tied to concrete cultural referents such as products and practices whose conceptual relevance is much more volatile over time. For example, many lexical innovations such as \ol{millennium bug}, which denotes the fear of a computer crash at the beginning of the new millennium, might show high rates of diffusion, and become entrenched and conventional among the majority of the speech community. Without continual conceptual relevance in public discourse, however, these words fail pass on to the next generation of speakers. S-curves are commonly expected when linguistic innovations compete for \hw{\enquote{semantic carrying capacity}}~\parencite{Nini2017ApplicationGrowth}. In most cases of \emph{lexical} innovation, however, the conceptual carrying capacity is not stable over time, but shows high degrees of variation as the use of new words is dependent on the salience of novel concepts in public discourse. This represents a critical deviation from the traditional assumptions behind S-curves in language change.

  ## Nevertheless, the strong theoretical and empirical basis of the S-curve model for the diffusion of linguistic and cultural innovations, and its explicit assumptions about the sociolinguistic dynamics underlying the process of diffusion make it an attractive \hw{blueprint} for the empirical study of the sociolinguistic diffusion of lexical innovations.

  \end{easylist}


  \subsection{Current framework: the EC-Model (Schmid 2020)}
    \label{subsec:ec-model}

  I use the Entrenchment-and-Conventionalization-Model~\parencite{Schmid2020DynamicsLinguistic} as a framework for modelling the diffusion of lexical innovations.

  The EC-Model provides an approach integrating both structural, cognitive and sociolinguistic perspectives on the diffusion of lexical innovations.

  The model also differentiates between the level of the individual (\enquote{entrenchment}) and the community (\enquote{conventionalization}).

  Here I will only briefly outline the most important concept relevant for studying the sociolinguistic aspects of diffusion here.

  \hw{Conventionalization}:

  definition: \enquote{Conventionalization is the continual process of establishing and re-adapting regularities of communicative behaviour among the members of a speech community, which is achieved by repeated usage activities in usage events and subject to the exigencies of the entrenchment processes taking place in the minds of speakers.}~\parencite{Schmid2020DynamicsLinguistic}

  \hw{Usualization} \enquote{Usualization can therefore be defined as a process that establishes, sustains, and changes regularities of behaviour with regard to co-semiotic mappings between forms and meanings or functions and communicative goals and linguistic forms. It affects the semasiological, onomasiological, syntagmatic, cotextual, and contextual dimensions of conformity behind conventionality and is relative to communities.}~\parencite{Schmid2020DynamicsLinguistic}

  \hw{Diffusion} \enquote{Linking the three aspects of speakers, cotexts, and contexts, I define diffusion as a process that brings about a change in the number of speakers and communities who conform to a regularity of co-semiotic behaviour and a change in the types of cotexts and contexts in which they conform to it.}~\parencite{Schmid2020DynamicsLinguistic}

  less relevant for sociolinguistic aspects and for this study
  cotexts
  contexts

  According to the EC-Model, for studying the sociolinguistic aspects of diffusion, investigating \enquote{changes in the number of speakers and communities} is thus essential.

\section{Measuring the diffusion of lexical innovations}
  \label{sec:measuring-diff}
  \subsection{Previous approaches}
    \label{subsec:previous-approaches}

  \begin{easylist}[itemize]

    # \hw{before frequency} Empirical approaches studying the diffusion of lexical innovations have only recently become feasible with the advent of new data sources and computational methods.

    # Earlier work had to rely on \hw{traditional linguistic corpora}. Due to the low-frequency nature of neologisms, general linguistic corpora do not allow to study representative sets of neologisms, which poses limits to drawing strong generalizations about the nature lexical innovation. Despite these limitations, case studies on selected neologisms~\parencite{Hohenhaus2006BouncebackabilityWebascorpusbased} and studies on specific domains of neology~\parencite{Elsen2004Neologismen} have managed to shed light on the spread of new words in more specific domains.

    # The advent of \hw{web corpora} in the last two decades has provided researchers with bigger and less formal data to study lexical innovation.

    ## The sheer size of big corpora $\rightarrow$ bigger samples

    ## monitoring corpora~\parencite{Davies2013CorpusNews}: tracking dynamics of diffusion, closer to coining

    ## In particular, a range of tools enabled the creation of specialized corpora for the investigation of neologisms.~\parencite{Renouf2006WebCorpIntegrated, Kerremans2012NeoCrawlerIdentifying,LemnitzerWortwarte,Gerard2017LogoscopeSemiautomatic,Cartier2017NeoveilleWeb}

    ## the nature of web corpus data is particularly suitable for investigating lexical innovations as
      ### language on the web is very creative,
      ### more informal sources, bigger spectrum of language use
      ### new words often first occur on the web
      ### and use on the web significantly influences whether these new formations catch on or not.

    ## Web corpora thus promise insights into diffusion across
      ### contexts: e.g. whether new words such as \ol{blockchain} are increasingly used in less formal
      ### cotexts: e.g. whether new words such as \ol{XXX} are increasingly used in more diverse cotexts

    # social media corpora \cite{Grieve2016AnalyzingLexical,Eisenstein2014DiffusionLexical}
    ## size
    ## nature: similar to web corpora
    ### creative, hotbed
    ### authentic language use
    ### driving force
    ## social network information

    # \hw{social network analysis} getting at \enquote{changes in the numbers and communities of speakers} by using social network information
    ## number of users: active and passive
    ## interactions between users: influencers
    ## network properties: density, centralization

  \end{easylist}

  \subsection{Going beyond frequency}
    \label{subsec:beyond-freq}

    The conventionality of linguistic units is commonly assessed by counting how often they are found to be used in linguistic corpora, with high frequencies of occurrence seen as indicators of high levels of conventionality. Diffusion as a process that drives increasing conventionalization is thus usually assumed to be reflected by increases in the usage frequency of linguistic innovations. Previous research on lexical innovation has largely been limited to this approach and has evaluated the spread and the overall success of new words on the basis of the number of tokens found in linguistic corpora. This paper takes usage frequency as a baseline and uses social network analysis to go beyond frequency to discover sociolinguistic dynamics of diffusion and conventionality that might have eluded previous frequency-based approaches.

    Frequency measures are widely used to study linguistic phenomena on all levels, from investigating phonological preferences between communities, to studying the increasing establishment of grammatical constructions like the \ol{going to}-future over time, to assessing the degree to which words are conventional lexical units of a language.

    Usage frequency is thus commonly used by a diverse set of linguistic sub-disciplines. From a structural perspective, for example, co-occurrence frequencies of multi-word units such as \ol{handsome man} are taken as an indicator for whether these are free combinations or more or less fixed collocations in a language system. Historical linguistics investigates phenomena like language change and grammaticalization, by analysing changes in usage frequency of certain constructions like the \ol{going to}-future over time. Cognitive and psycholinguistic research usually relies on frequency measures to approximate the degree to which speakers are familiar with words that are presented as linguistic stimuli in experiments to control for effects on experimental results. \todo{This paragraph is unnecessary.}

    The reliance on usage frequency as a measure for different phenomena in these diverse research contexts has faced substantial criticism. \cite{Stefanowitsch2017CorpusbasedPerspective} provide a good overview of the theoretical assumptions and problems that underlie frequency-based approaches in corpus linguistics.

    \todo{freq. esp. insufficient for lex. inn.}
    % as new words are
    (1) highly socially indexical and thus especially prone to be used only by certain sub-communities,
    (2) topical which makes freq. less reliable bc. it fails to capture \enquote{dormant} passive knowledge of the words

    When assessing the suitability of usage frequency as a measure for the diffusion and conventionality of neologisms a set of assumptions underlying the frequency-based approach need to be disentangled. While these theoretical and methodological considerations generally apply to all corpus-linguistic work, the focus will be on the current issue of lexical innovation.

    I adopt Schmid's EC-Model~\parencite{Schmid2020DynamicsLinguistic} as a framework for defining and delimitating the concepts of \enquote{conventionalization} and \enquote{diffusion}.

    \begin{quote}
    [\dots] I define diffusion as a process that brings about a change in the number of speakers and communities who conform to a regularity of co-semiotic behaviour and a change in the types of cotexts and contexts in which they conform to it.
    \end{quote}

    Aside from the sociolinguistic perspective on diffusion (\enquote{number of speakers and communities}), Schmid conceptualizes diffusion as a multi-dimensional process that also takes into account changes on the syntagmatic (\enquote{cotexts}) and pragmatic (\enquote{contexts}) level. This paper will focus on the sociolinguistic dimension of diffusion and will leave an integrative approach including all three perspectives for further research.

    Applying this definition to the context of lexical innovation thus implies that the successful diffusion of a new word is marked by it being known and used by an increasing \enquote{number of speakers and communities}.

    By contrast, in a strict sense, usage frequency counts of a lexeme represent the total number of tokens produced by \emph{all} speakers who have \emph{contributed} to the \emph{target text corpus}. The discrepancy between the theoretical definition of diffusion adopted here and the exact information contained by frequency show that this operationalization relies on a number of assumptions that let it only approximate the construct to be measured.

    Firstly, usage frequency does not provide direct information as to how many \emph{individual speakers} have used a new word. Especially in the case of neology, there are certain new words that are disproportionally used and propagated by a relatively small, but more active and dedicated users of the new term. This leads to high overall frequency counts which falsely suggest that larger parts of the speech community have adopted the term.

    Secondly, usage frequency only captures active uses of a term and fails to include how many speakers have been passively exposed to neologisms. In the context of entrenchment, \textcite{Stefanowitsch2017CorpusbasedPerspective} refer to this problem as the \enquote{corpus-as-input} and \enquote{corpus-as-output} hypotheses. The underlying assumption is that the output of the speakers who have contributed to a corpus can serve as an approximation for the potential linguistic input of a comparable speaker group. Frequency thus reflects the \enquote{usage intensity} of neologisms in the speech community, which in turn indicates the degree of entrenchment in individual speakers as well as an approximation of the conventionality of the neologisms in the speech community. In the case of lexical innovation this can be problematic as questionnaires studies on the use of neologisms~\parencite{Kerremans2015WebNew} show that many speakers report that they have come across target neologisms, but have not actively used them in discourse. Relying on frequency counts only can thus often lead to under- or overestimating the degree of diffusion of neologisms.

    Thirdly, usage frequency fails to capture where new words diffuse across \enquote{communities of speakers}, as suggested by Schmid's definition. This is, of course, a consequence of the fact that frequency counts cannot provide direct information about the number of speakers involved in the diffusion of neologisms, as was pointed out in the first two points above. New words often stem and quickly spread within tight-knit communities of practice that share common attitudes or interests. Frequency measures alone cannot detect whether neologisms only show increasing usualization within these groups or whether they diffuse and become conventional in other parts of the speech community, which represents an essential feature of the sociolinguistic dimension of diffusion.


    how much the words might have diffused outside the \emph{target text corpus}

    temporal dynamics (e.g. \ol{millennium bug})


\section{`Interactional' networks}

      The resulting networks are interactional rather than static.~\parencite{Goel2016SocialDynamics} This makes them more similar to communities of practice than to traditional sociolinguistic networks based on static speaker characteristics such socio-economic status.
      In the case of lexical innovation networks that are based on whether speakers provide valuable information. In cases such as \emph{alt-left}, for example, interactional networks show whether usage of the term remains centralized to a tight-knit community of speakers or whether it diffuses to be used by other sub-communities.
      Whether communities are distinct depends on whether users communicate with each other. While the reasons for theses communicative affiliations remain unknown (age, gender, socio-economic status), they are certainly real in mutually engage in communicative interaction. (community = communication)
      It would be interesting to complement this information with static information (e.g. census data \parencite{Eisenstein2014DiffusionLexical}), however such data are currently not obtainable (geotags no longer provided, hard to infer; difficult to predict plus circular (e.g. gender)).
`

\section{Limitations of usage frequency}

  In a strict sense, usage frequency only captures how many tokens of a word were produced by all speakers who have contributed to the corpus at hand. Investigating the degree to which new words diffuse to new speakers and speaker communities on the basis of frequency counts thus depends on several inferences that are commonly accepted as sufficiently reliable.

  \begin{enumerate}
    \item Frequency counts indicate how many speakers have used the term.
    \item The number of speakers who have used the term indicates how many speakers are familiar with the term, whether they have actively used it or not.
    \item The number of speakers who are familiar with the term indicate how many communities of speakers are familiar with the term.
  \end{enumerate}

  These assumptions are to a large extent plausible and have empirically been proven to be effective for investigating both degrees of entrenchment of lexemes in individual speakers as well their conventionality in the speech community.

\section{last call}

  \subsection{Introduction}

    Sociological research has been concerned with pressing issues regarding the impact of online social networks for the spread of hate speech, fake news and the power of \enquote{influencers}, bots and institutions on public opinions and elections, which increasingly strain the social fabric.\todo{should probably be removed}

  \subsection{Summary of frequency-based approach}

    So far, I have used frequency-based visualisations and metrics to assess different degrees of diffusion of the neologisms in the sample. In the first step, I used the most common measure for assessing the conventionality of new words: their total frequency of occurrence in the corpus. In the following steps, I extended the frequency-based approach by including temporal information in the analysis. Zooming in on the temporal dynamics of use identified different pathways of diffusion. Notably, it revealed substantial differences in the diachronic usage profiles of neologisms with comparable total frequency.

    Within the group of selected neologisms, \ol{hyperlocal}, \ol{solopreneur}, and \ol{alt-left}, for example, would all be placed in the medium range of the conventionality continuum if grouped by total usage frequency alone, as presented in Table~\ref{subtab:freq-total-cases}. Taking this most basic measure as an indicator of degrees of diffusion, it would seem that these words are roughly equally conventional among users on Twitter. However, adding the temporal dynamics of their use in the corpus to the picture revealed significant differences between their diachronic usage profiles, which seems important for assessing their pathways and degrees of diffusion in a more differentiated and accurate way.

    Visualising the cumulative increase in uses over time (Table~\ref{fig:freq_cum_cases}) for \ol{hyperlocal}, for example, shows a stable linear trend, which indicates that its total frequency count has been the product of relatively consistent use over its relatively long lifespan. Its temporal usage profile in Figure~\ref{subfig:freq_temp_hyperlocal} confirms these observations and presents its initial period of accelerated diffusion followed by an extended stable level of relatively consistent use over the last five years of its observed lifespan. This consistency is further corroborated by its low coefficient of variation (Table~\ref{subtab:coef-var-cases}). In sum, the balanced nature of this frequency-based usage profile suggests a relatively organic trajectory of diffusion, culminating in a solid degree of conventionality in the recent past. The fact that \ol{hyperlocal} was added to the OED in 2015 supports these observations. \todo{paragraph needs revision}

    By comparison, \ol{solopreneur} has a slightly higher overall frequency of occurrence in the corpus, yet its use is less stable over time. While its overall lifespan is similar to that of \ol{hyperlocal}, its cumulative distribution shows that the majority of its use goes back to a relative short period of intensive use, after which it exhibits a slightly negative trend in later stages. Both the visualization of its temporal frequency profile as well as its coefficient of variation demonstrate a higher degree of fluctuation in its popularity. This temporal usage profile suggests that its diffusion was influenced significantly by effects of topical salience. While \ol{solopreneur} has been used in a high total number of tweets in the corpus, it thus seems less certain whether its use will become stable over time, and to what degree its use extends beyond the entrepreneurial community which triggered the main spurt of its diffusion in the second half of 2014.

    Lastly, \ol{alt-left} is in the same range of total usage frequency, but its use is much more unevenly dispersed across the corpus than that of the remaining selected neologisms. The term is much younger, and its cumulative increase in uses illustrates that diffusion is largely limited to a very short, highly intensive period of use, after which it shows a strong negative trend in its usage frequency. Its diachronic frequency profile and its coefficient of variation correspondingly demonstrate very high volatility in its use. Since the short period of intense use of \ol{alt-left} can clearly be traced back to participants of the Unite the Right Rally in Charlottesville in August 2017, it seems plausible that its popularity has never extended beyond this topical event and beyond this particular community of like-minded individuals.\todo{mention \ol{upskill}, potentially in place of \ol{hyperlocal}}

  \subsection{Future work}

    \subsubsection{1}

      While the present paper has attempted to assess the potential of frequency network-based approaches, a more extensive evaluation will have to be left for future work. A more rigorous attempt could include a systematic evaluation on the basis of external data sources like web corpora or online dictionaries. Moreover, questionnaires could be used to determine to what degree corpus-based measures generalise and converge with speaker judgements~(s. \textcite{Kerremans2015WebNew} for an earlier attempt using a smaller sample of neologisms).

      Furthermore, initial results in the present study suggested that social network information might be informative for predicting the success of lexical innovations. Using statistical models to test the predictive power of social network information, possibly in combination with temporal information, constitutes an attractive objective for future work, which might also provide insights about the determining factors of diffusion~\parencite{Ryskina2020WhereNew, Stewart2018MakingFetch}.

      Lastly, the present results demonstrated that neologisms show different degrees of social diffusion between speakers and communities. The broader definition by \textcite{Schmid2020DynamicsLinguistic} also includes diffusion across \enquote{contexts} and \enquote{cotexts}, however. To study the former, it would seem desirable to investigate to what degrees neologisms diffuse across different usage contexts, e.g. different web registers~\parencite{Biber2016RegisterVariation}. To study the latter, future work could continue to investigate to what degree the use of neologisms differs between communities~\parencite{Tredici2019YouShall,Schmid2020BattlingSemantica}.

    \subsubsection{2}

      The present study has analysed the pathways and degrees of diffusion of neologisms on Twitter. Aside from an in-depth study of the spread of the neologisms in the sample, the aim of this paper was to apply and assess a range of frequency and network-based measures to study the diffusion of neologisms to new speakers and communities. It was shown that investigating the temporal and social dynamics underlying the use of neologisms is crucial for a more detailed and accurate assessment of their social diffusion in the speech community.

  \subsection{SNA}

    As discussed in Section~NN, from a theoretical, sociolinguistic perspective, the degree of diffusion of lexical innovations depends on the degree to which new words become conventional among new speakers and communities of speakers. Frequency-based analyses, as presented in the previous section, can by definition only provide information about the distribution of occurrences of neologisms in the corpus; they cannot provide direct evidence about the size and composition of the community of speakers who have produced the observed attestations. Social network analysis, by contrast, is based on data about the communicative behaviour of speakers in the corpus and can thus provide direct insights into the social characteristics of the speech community. This allows for a more direct operationalization of the theoretical model of diffusion. The structural characteristics of the social network of speakers who have used a target neologism can be used to assess whether the term has been used by large swaths of the speech community, or whether its use remains limited to certain pockets of the speech community.

  \subsection{Theoretical framework}

          \enquote{communities of practice} \parencite{Leuckert2020ChapterDigital}
          \todo{definition}

          The resulting networks are interactional rather than static.~\parencite{Goel2016SocialDynamics} This makes them more similar to communities of practice than to traditional sociolinguistic networks based on static speaker characteristics such socio-economic status.
          In the case of lexical innovation, networks that are based on the interactions of speakers provide valuable information. In cases such as \emph{alt-left}, for example, interactional networks show whether usage of the term remains centralized to a tight-knit community of speakers or whether it diffuses other sub-communities.
          Whether communities are distinct depends on whether users communicate with each other. While the reasons for theses communicative affiliations remain unknown (age, gender, socio-economic status), they are real in that users mutually engage in communicative interaction. (community = communication)
          It would be interesting to complement this information with static information (e.g. census data \parencite{Eisenstein2014DiffusionLexical}), however such data are currently not obtainable (geotags no longer provided, hard to infer; difficult to predict plus circular (e.g. gender)).
